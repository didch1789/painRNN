{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK GENERATOR\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "class PainTaskGenerator(Dataset):\n",
    "    def __init__(self, task_dict):\n",
    "        # INPUT DIMENSIONS\n",
    "        self.stimulus_condition = task_dict['stimulus_condition'] # stimulus intensity\n",
    "        self.onset_offset_noise  = task_dict['onset_offset_noise'] # mean and std\n",
    "        self.stimulus_intensities = task_dict['stimulus_intensities'] \n",
    "        # TIME SETTINGS\n",
    "        self.epoch_onsets = task_dict['epoch_onsets']\n",
    "        self.epoch_durations = task_dict['epoch_durations']\n",
    "        self.trial_length = task_dict['trial_length']\n",
    "        assert len(self.epoch_onsets) == len(self.epoch_durations)\n",
    "        # ETCs...\n",
    "        self.pain_temperature = task_dict['pain_temperature']\n",
    "        self.warmth_temperature = task_dict['warmth_temperature']\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ITEMS TO RETURN\n",
    "        n_epochs  = len(self.epoch_onsets)\n",
    "        input_seq = np.zeros((3, self.trial_length))\n",
    "        output_seq = np.zeros((3, self.trial_length))\n",
    "        pain_condition = self.stimulus_condition\n",
    "\n",
    "        # 1. input_seq. 3 dim. \n",
    "        # dim 1 for continous stimulus intensities.\n",
    "        # dim 2 for warmth indicator \n",
    "        # dim 3 for pain indicator (above 46)\n",
    "        # e.g. for dim 2 & 3\n",
    "        # [0 0 1 1 1 1 1 1 1 1 0 0;\n",
    "        #  0 0 0 0 1 1 1 0 0 0 0 0]\n",
    "        for i in range(n_epochs):\n",
    "            fromm       = self.epoch_onsets[i] \n",
    "            tilll       = fromm + self.epoch_durations[i]\n",
    "            onset_stim  = self.stimulus_intensities[i][0]\n",
    "            offset_stim = self.stimulus_intensities[i][1]\n",
    "            input_seq[0, fromm:tilll] = np.linspace(onset_stim, offset_stim, num=tilll-fromm) \n",
    "        input_seq[1, :] = input_seq[0, :] >= self.warmth_temperature\n",
    "        input_seq[2, :] = input_seq[0, :] >= self.pain_temperature\n",
    "\n",
    "        # 2. output_seq. 3 dim.\n",
    "        # dim 1 for continuous ratings. (requires behavioral model first...?)\n",
    "        # dim 2 for not pain indicator [pain as 1, non-pain as 0] with noise added.\n",
    "        # dim 3 for 1 - dim2\n",
    "        \n",
    "        output_seq[0, :] = gaussian_filter1d(np.roll(input_seq[0, :], 2), sigma=1) \n",
    "        # THIS NEEDS MODIFICATION. \"np.convolve\"... gaussian_filter1d takes zero mean gaussian distribution which is not likely the case of the \"lagged\" behavioral consequences.\n",
    "        \n",
    "        onset_offset_noise = self.onset_offset_noise\n",
    "        pain_onset = np.rint(np.random.normal(onset_offset_noise[0][0], onset_offset_noise[0][1], 1)).astype(int)[0]\n",
    "        pain_offset = np.rint(np.random.normal(onset_offset_noise[1][0], onset_offset_noise[1][1], 1)).astype(int)[0]\n",
    "\n",
    "        output_seq[1, :pain_onset] = 1\n",
    "        output_seq[1, pain_onset:pain_offset] = 0\n",
    "        output_seq[1, pain_offset:] = 1\n",
    "        output_seq[2, :] = 1 - output_seq[1, :]\n",
    "\n",
    "\n",
    "        return {'input_seq': input_seq, 'output_seq': output_seq,\n",
    "                'pain_onoffset': (pain_onset, pain_offset), 'condition': pain_condition}\n",
    "        \n",
    "        # For output dim 1 convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Task Params\n",
    "stim_ints   = [43, 44, 45, 46.5, 47, 47.5]\n",
    "conditions  = [\"141\", \"151\", \"161\", \"242\", \"252\", \"262\", \"343\", \"353\", \"363\"]\n",
    "stimulus_intensities = []\n",
    "for cond_i in range(len(conditions)):\n",
    "    start_end_temp = stim_ints[int(conditions[cond_i][0]) - 1]\n",
    "    middle_temp = stim_ints[int(conditions[cond_i][1]) - 1]\n",
    "    stimulus_intensities.append([[25, start_end_temp], [start_end_temp, start_end_temp], \n",
    "                                   [start_end_temp, middle_temp], [middle_temp, middle_temp], \n",
    "                                   [middle_temp, start_end_temp], [start_end_temp, start_end_temp],\n",
    "                                   [start_end_temp, 25]])\n",
    "onoffset_noise = [(14, 1), [23, 1]]\n",
    "\n",
    "# Check\n",
    "int_cond = 0     \n",
    "task_params = {'stimulus_condition': conditions[int_cond],\n",
    "                'stimulus_intensities': stimulus_intensities[int_cond],\n",
    "                'onset_offset_noise': onoffset_noise,\n",
    "                'epoch_onsets':    [0, 2, 8, 17, 22, 31, 37],\n",
    "                'epoch_durations': [2, 6, 9, 5, 9, 6, 2],\n",
    "                'trial_length': 39, # 0 - 39 sec\n",
    "                'pain_temperature': 46,\n",
    "                'warmth_temperature': 40} \n",
    "data = PainTaskGenerator(task_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PainTaskGenerator at 0x1368fab10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN class define\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = 'mps'\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__() # 1. WHAT IS THIS?\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rnn_layer = nn.RNN(input_dim, hidden_dim, nonlinearity=\"relu\", dropout=1/8, batch_first=True) # batch_first = True => Input's first dim is the batch size\n",
    "                                                                         # 3rd input num_layer which means vertically extended layer.\n",
    "        self.fc_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x): # What is X? ... model(input) == model.forward(input). input => # batch x time x hidden_dim\n",
    "        hidden = torch.zeros(x.size(0), x.size(1), self.hidden_dim) \n",
    "        output = torch.zeros(x.size(0), x.size(1), self.output_dim)\n",
    "        \n",
    "        h_t    = torch.zeros(x.size(0), self.hidden_dim).to(device)\n",
    "        for t in range(x.size(1)): # iteration for time\n",
    "                                   # this part depends on how precise we want to model the neural activity.\n",
    "                                   # this is just for the computation. just using vanila RNN\n",
    "            o_t, h_t = self.rnn_layer(x[:, t, :])\n",
    "            hidden[:, t, :] = h_t\n",
    "            output[:, t, :] = o_t\n",
    "        return output, hidden\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dt):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.i2h = nn.Linear(input_dim, hidden_dim)\n",
    "        self.h2h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.h2o = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(x.size(0), x.size(1), self.hidden_dim)\n",
    "        output = torch.zeros(x.size(0), x.size(1), self.output_dim)\n",
    "\n",
    "        h = torch.zeros(x.size(0), self.hidden_dim).to(device)\n",
    "        for t in range(x.size(1)):\n",
    "            h = h * (1 - self.dt/self.tau) + (self.dt/self.tau) * torch.relu(self.i2h(x[:,t,:]) + self.h2h(h))\n",
    "            o = self.h2o(h)\n",
    "            hidden[:,t,:] = h\n",
    "            output[:,t,:] = o\n",
    "        return output, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNN.__init__() missing 1 required positional argument: 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m RNN(input_dim, hidden_dim, output_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "\u001b[0;31mTypeError\u001b[0m: RNN.__init__() missing 1 required positional argument: 'dt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 18\n",
    "num_epochs = 3000\n",
    "learning_rate = 1e-2\n",
    "trial_length = 39\n",
    "input_dim  = 3\n",
    "output_dim  = 3\n",
    "hidden_dim = 8\n",
    "device = 'mps'\n",
    "model = RNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.zeros((batch_size, trial_length, input_dim))\n",
    "    targets = torch.zeros((batch_size, trial_length, output_dim))\n",
    "    for i in range(batch_size):\n",
    "        int_cond = i % 9\n",
    "        task_params = {'stimulus_condition': conditions[int_cond],\n",
    "                'stimulus_intensities': stimulus_intensities[int_cond],\n",
    "                'onset_offset_noise': onoffset_noise,\n",
    "                'epoch_onsets':    [0, 2, 8, 17, 22, 31, 37],\n",
    "                'epoch_durations': [2, 6, 9, 5, 9, 6, 2],\n",
    "                'trial_length': 39, # 0 - 39 sec\n",
    "                'pain_temperature': 46,\n",
    "                'warmth_temperature': 40} # This part + condition indexing can be incorporated in the \"PainTaskGenerator\"\n",
    "        single_cond       = PainTaskGenerator(task_params)\n",
    "        single_cond_trial = single_cond[0]\n",
    "        inputs[i], targets[i] = torch.tensor(single_cond_trial['input_seq'].T), torch.tensor(single_cond_trial['input_seq'].T)\n",
    "\n",
    "    inputs.to(device)\n",
    "    targets.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # outputs.grad()\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print (f'Training epoch ({epoch+1}/{num_epochs}), Loss: {loss.item():3.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 512\n",
    "Button_threshold = 0.9\n",
    "dataset = PainTaskGenerator(task_params)\n",
    "with torch.no_grad():\n",
    "    inputs = torch.zeros((test_batch_size, trial_length, input_dim))\n",
    "    targets = torch.zeros((test_batch_size, trial_length, output_dim))\n",
    "    for i in range(test_batch_size):\n",
    "        data = dataset[i]\n",
    "        inputs, targets = torch.tensor(data['input_seq']).T, torch.tensor(data['output_seq']).T\n",
    "    targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VisualDiscrimination' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      2\u001b[0m test_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mVisualDiscrimination\u001b[49m(task_params_test)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((test_batch_size, trial_steps, input_dim))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VisualDiscrimination' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "test_batch_size = 512\n",
    "\n",
    "dataset = PainTaskGenerator(task_params)\n",
    "with torch.no_grad():\n",
    "    inputs = torch.zeros((test_batch_size, trial_length, input_dim))\n",
    "    targets = torch.zeros((test_batch_size, trial_length, output_dim))\n",
    "    for i in range(test_batch_size):\n",
    "        data = dataset[i]\n",
    "        inputs[i], targets[i] = torch.tensor(data['input_seq']).T, torch.tensor(data['output_seq']).T\n",
    "    inputs.to(device)\n",
    "\n",
    "    outputs, hidden_state = model(inputs)\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    hidden_state = hidden_state.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "\n",
    "pca_model = PCA(n_components=3)\n",
    "pca_model.fit(hidden_state.reshape(-1,hidden_dim))\n",
    "reduced_hidden_state = np.zeros((test_batch_size, trial_steps, 3))\n",
    "for i in range(test_batch_size):\n",
    "    reduced_hidden_state[i] = pca_model.transform(hidden_state[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimulus_condition': '363',\n",
       " 'stimulus_intensities': [[25, 45],\n",
       "  [45, 45],\n",
       "  [45, 47.5],\n",
       "  [47.5, 47.5],\n",
       "  [47.5, 45],\n",
       "  [45, 45],\n",
       "  [45, 25]],\n",
       " 'onset_offset_noise': [(14, 1), [23, 1]],\n",
       " 'epoch_onsets': [0, 2, 8, 17, 22, 31, 37],\n",
       " 'epoch_durations': [2, 6, 9, 5, 9, 6, 2],\n",
       " 'trial_length': 39,\n",
       " 'pain_temperature': 46,\n",
       " 'warmth_temperature': 40}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('env_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76704af79bdacbe9e3295deab26431e84c2830fb3934619e845f35b49385e555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
