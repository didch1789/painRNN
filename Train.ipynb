{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/5000], Loss: 0.6575 in 1 of 10\n",
      "Epoch [20/5000], Loss: 0.4635 in 1 of 10\n",
      "Epoch [30/5000], Loss: 0.4373 in 1 of 10\n",
      "Epoch [40/5000], Loss: 0.3930 in 1 of 10\n",
      "Epoch [50/5000], Loss: 0.3470 in 1 of 10\n",
      "Epoch [60/5000], Loss: 0.3769 in 1 of 10\n",
      "Epoch [70/5000], Loss: 0.3512 in 1 of 10\n",
      "Epoch [80/5000], Loss: 0.3284 in 1 of 10\n",
      "Epoch [90/5000], Loss: 0.3617 in 1 of 10\n",
      "Epoch [100/5000], Loss: 0.3585 in 1 of 10\n",
      "Epoch [110/5000], Loss: 0.3575 in 1 of 10\n",
      "Epoch [120/5000], Loss: 0.3351 in 1 of 10\n",
      "Epoch [130/5000], Loss: 0.3130 in 1 of 10\n",
      "Epoch [140/5000], Loss: 0.3219 in 1 of 10\n",
      "Epoch [150/5000], Loss: 0.3141 in 1 of 10\n",
      "Epoch [160/5000], Loss: 0.3321 in 1 of 10\n",
      "Epoch [170/5000], Loss: 0.3242 in 1 of 10\n",
      "Epoch [180/5000], Loss: 0.3036 in 1 of 10\n",
      "Epoch [190/5000], Loss: 0.3073 in 1 of 10\n",
      "Epoch [200/5000], Loss: 0.2917 in 1 of 10\n",
      "Epoch [210/5000], Loss: 0.3417 in 1 of 10\n",
      "Epoch [220/5000], Loss: 0.3025 in 1 of 10\n",
      "Epoch [230/5000], Loss: 0.3035 in 1 of 10\n",
      "Epoch [240/5000], Loss: 0.3115 in 1 of 10\n",
      "Epoch [250/5000], Loss: 0.3128 in 1 of 10\n",
      "Epoch [260/5000], Loss: 0.2854 in 1 of 10\n",
      "Epoch [270/5000], Loss: 0.3127 in 1 of 10\n",
      "Epoch [280/5000], Loss: 0.3091 in 1 of 10\n",
      "Epoch [290/5000], Loss: 0.3207 in 1 of 10\n",
      "Epoch [300/5000], Loss: 0.3264 in 1 of 10\n",
      "Epoch [310/5000], Loss: 0.3105 in 1 of 10\n",
      "Epoch [320/5000], Loss: 0.3165 in 1 of 10\n",
      "Epoch [330/5000], Loss: 0.2937 in 1 of 10\n",
      "Epoch [340/5000], Loss: 0.3097 in 1 of 10\n",
      "Epoch [350/5000], Loss: 0.3132 in 1 of 10\n",
      "Epoch [360/5000], Loss: 0.3011 in 1 of 10\n",
      "Epoch [370/5000], Loss: 0.2881 in 1 of 10\n",
      "Epoch [380/5000], Loss: 0.3254 in 1 of 10\n",
      "Epoch [390/5000], Loss: 0.3085 in 1 of 10\n",
      "Epoch [400/5000], Loss: 0.3041 in 1 of 10\n",
      "Epoch [410/5000], Loss: 0.2936 in 1 of 10\n",
      "Epoch [420/5000], Loss: 0.3055 in 1 of 10\n",
      "Epoch [430/5000], Loss: 0.3074 in 1 of 10\n",
      "Epoch [440/5000], Loss: 0.3066 in 1 of 10\n",
      "Epoch [450/5000], Loss: 0.2968 in 1 of 10\n",
      "Epoch [460/5000], Loss: 0.3144 in 1 of 10\n",
      "Epoch [470/5000], Loss: 0.3061 in 1 of 10\n",
      "Epoch [480/5000], Loss: 0.3097 in 1 of 10\n",
      "Epoch [490/5000], Loss: 0.3140 in 1 of 10\n",
      "Epoch [500/5000], Loss: 0.3165 in 1 of 10\n",
      "Epoch [510/5000], Loss: 0.3078 in 1 of 10\n",
      "Epoch [520/5000], Loss: 0.3334 in 1 of 10\n",
      "Epoch [530/5000], Loss: 0.3114 in 1 of 10\n",
      "Epoch [540/5000], Loss: 0.2915 in 1 of 10\n",
      "Epoch [550/5000], Loss: 0.3052 in 1 of 10\n",
      "Epoch [560/5000], Loss: 0.3007 in 1 of 10\n",
      "Epoch [570/5000], Loss: 0.3076 in 1 of 10\n",
      "Epoch [580/5000], Loss: 0.3248 in 1 of 10\n",
      "Epoch [590/5000], Loss: 0.2967 in 1 of 10\n",
      "Epoch [600/5000], Loss: 0.3056 in 1 of 10\n",
      "Epoch [610/5000], Loss: 0.2797 in 1 of 10\n",
      "Epoch [620/5000], Loss: 0.2888 in 1 of 10\n",
      "Epoch [630/5000], Loss: 0.3057 in 1 of 10\n",
      "Epoch [640/5000], Loss: 0.2990 in 1 of 10\n",
      "Epoch [650/5000], Loss: 0.3279 in 1 of 10\n",
      "Epoch [660/5000], Loss: 0.2630 in 1 of 10\n",
      "Epoch [670/5000], Loss: 0.2930 in 1 of 10\n",
      "Epoch [680/5000], Loss: 0.2667 in 1 of 10\n",
      "Epoch [690/5000], Loss: 0.2854 in 1 of 10\n",
      "Epoch [700/5000], Loss: 0.2858 in 1 of 10\n",
      "Epoch [710/5000], Loss: 0.2838 in 1 of 10\n",
      "Epoch [720/5000], Loss: 0.2919 in 1 of 10\n",
      "Epoch [730/5000], Loss: 0.2948 in 1 of 10\n",
      "Epoch [740/5000], Loss: 0.3153 in 1 of 10\n",
      "Epoch [750/5000], Loss: 0.2799 in 1 of 10\n",
      "Epoch [760/5000], Loss: 0.2974 in 1 of 10\n",
      "Epoch [770/5000], Loss: 0.2908 in 1 of 10\n",
      "Epoch [780/5000], Loss: 0.3173 in 1 of 10\n",
      "Epoch [790/5000], Loss: 0.2873 in 1 of 10\n",
      "Epoch [800/5000], Loss: 0.2869 in 1 of 10\n",
      "Epoch [810/5000], Loss: 0.2829 in 1 of 10\n",
      "Epoch [820/5000], Loss: 0.3000 in 1 of 10\n",
      "Epoch [830/5000], Loss: 0.2871 in 1 of 10\n",
      "Epoch [840/5000], Loss: 0.2563 in 1 of 10\n",
      "Epoch [850/5000], Loss: 0.2846 in 1 of 10\n",
      "Epoch [860/5000], Loss: 0.2850 in 1 of 10\n",
      "Epoch [870/5000], Loss: 0.2843 in 1 of 10\n",
      "Epoch [880/5000], Loss: 0.2875 in 1 of 10\n",
      "Epoch [890/5000], Loss: 0.2699 in 1 of 10\n",
      "Epoch [900/5000], Loss: 0.3048 in 1 of 10\n",
      "Epoch [910/5000], Loss: 0.2913 in 1 of 10\n",
      "Epoch [920/5000], Loss: 0.3035 in 1 of 10\n",
      "Epoch [930/5000], Loss: 0.2896 in 1 of 10\n",
      "Epoch [940/5000], Loss: 0.2998 in 1 of 10\n",
      "Epoch [950/5000], Loss: 0.2910 in 1 of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 211\u001b[0m\n\u001b[1;32m    208\u001b[0m         loss_name    \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActions\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    210\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 211\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    212\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    214\u001b[0m loss_epochs\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 24.11.25\n",
    "# Searching all possible hyperparam space.\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import PainRNN as PainRNN\n",
    "\n",
    "param = dict()\n",
    "param['level']      = ['condition_prob'] #  'trial', 'condition', 'condition_prob', 'threshold_mdl1'\n",
    "param['activation'] = ['relu'] \n",
    "param['outputs']    = ['Actions', 'Ratings', 'Clicks2'] # 'Actions', 'Clicks', , 'Both_MSE'\n",
    "param['alphas']     = np.linspace(0, 1, 101)\n",
    "param['alphas']     = param['alphas'][1:]\n",
    "n_alphas            = len(param['alphas'])\n",
    "\n",
    "# Clicks. CE \n",
    "# Ratings. MSE\n",
    "# Both (Ratings + Clicks). MSE + CE or MSE\n",
    "# Actions (Ratings + Click1 + Click2; Click1 - Click2 for deciding actions indicated as 0 or 1 for pain). MSE + CE or MSE \n",
    "\n",
    "# FIXED PARAMS\n",
    "input_size    = 1   # Input feature size (objective temperature)\n",
    "hidden_size   = 30  # Number of features in the hidden state\n",
    "noise_sig     = 1e-1\n",
    "learning_rate = 1e-3 \n",
    "n_epochs      = 5000\n",
    "device        = 'cpu' # mps\n",
    "results_name  = f'results_hdsz{hidden_size}_nepch{n_epochs}'\n",
    "# batch_size  = 50 for trial-level 9 for condition-level\n",
    "\n",
    "# Seed random number generator for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Training models for every search space\n",
    "for i_lvl, name_lvl in  enumerate(param['level']):\n",
    "    for i_act, name_act in enumerate(param['activation']):\n",
    "        for i_out, name_out in enumerate(param['outputs']):\n",
    "            \n",
    "            targfolder  = os.path.join(os.getcwd(), results_name, f'{name_lvl}_act-{name_act}_label-{name_out}')\n",
    "            if not (os.path.isdir(targfolder)):\n",
    "                os.makedirs(targfolder)\n",
    "            \n",
    "            # Specifying Inputs\n",
    "            if name_lvl == 'trial':\n",
    "                inputoutputs = sio.loadmat('InOutputs.mat')\n",
    "                Inputs   = inputoutputs['Inputs']\n",
    "                Outputs  = inputoutputs['Outputs']\n",
    "                Xnp = []\n",
    "                ynp = []\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    Xnp.append(np.tile(Inputs[cond_i, :], (Outputs[cond_i][0].shape[0], 1)))\n",
    "                    ynp.append(Outputs[cond_i][0])\n",
    "                Xnp = np.expand_dims(np.vstack(Xnp), axis=2)\n",
    "                ynp = np.vstack(ynp)\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 50\n",
    "                \n",
    "            elif name_lvl == 'condition':\n",
    "                inputoutputs = sio.loadmat('InOutputs_condavg.mat')\n",
    "                Inputs   = inputoutputs['Inputs']\n",
    "                Outputs  = inputoutputs['Outputs']\n",
    "                Xnp      = np.expand_dims(Inputs, axis = 2)\n",
    "                ynp      = []\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    ynp.append(Outputs[cond_i][0])\n",
    "                ynp         = np.stack(ynp, axis = 0)\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 9\n",
    "                \n",
    "            elif name_lvl == 'threshold_mdl1':\n",
    "                inputoutputs = sio.loadmat('model_v1_InOutputs_condavg.mat')\n",
    "                Inputs   = inputoutputs['Inputs']\n",
    "                Outputs  = inputoutputs['Outputs']\n",
    "                Xnp      = np.expand_dims(Inputs, axis = 2)\n",
    "                ynp      = []\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    ynp.append(Outputs[cond_i][0])\n",
    "                ynp         = np.stack(ynp, axis = 0)\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 9\n",
    "            \n",
    "            elif name_lvl == 'condition_prob':\n",
    "                inputoutputs = sio.loadmat('InOutputs_condavg_prob.mat')\n",
    "                n_condsample = 100\n",
    "                n_times      = inputoutputs['Inputs'].shape[1]\n",
    "                Inputs       = inputoutputs['Inputs']\n",
    "                Outputs      = inputoutputs['Outputs']\n",
    "                Xnp          = np.empty(shape=(n_condsample * 9, n_times, 1))\n",
    "                ynp          = np.empty(shape=(n_condsample * 9, n_times, 2))\n",
    "                \n",
    "                k = 0\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    input = Inputs[cond_i]\n",
    "                    for sample_i in range(n_condsample):\n",
    "                        clicks = np.zeros((n_times))\n",
    "                        rating = Outputs[cond_i, 0]\n",
    "                        click1 = round(np.random.normal(loc=Outputs[cond_i, 1][0][0], scale=Outputs[cond_i, 1][0][1]))\n",
    "                        click2 = round(np.random.normal(loc=Outputs[cond_i, 1][0][2], scale=Outputs[cond_i, 1][0][3]))\n",
    "                        if click1 > click2:\n",
    "                            click2 = click1+1\n",
    "                        if click2 > n_times:\n",
    "                            click2 = n_times\n",
    "                        clicks[click1:click2] = 1\n",
    "                        Xnp[k, :, 0] = input\n",
    "                        ynp[k, :, 0] = np.squeeze(rating)\n",
    "                        ynp[k, :, 1] = clicks\n",
    "                        k = k + 1\n",
    "\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 200\n",
    "\n",
    "            # Combine inputs and outputs into a dataset\n",
    "            dataset    = TensorDataset(X, y)\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            if (name_out == 'Clicks') or (name_out == 'Ratings') :\n",
    "                output_size = 1\n",
    "            elif ('Both' in name_out) or (name_out == 'Clicks2'):\n",
    "                output_size = 2\n",
    "            elif name_out == 'Actions':\n",
    "                output_size = 3\n",
    "            \n",
    "            # Model instantiation\n",
    "            for i, alpha in enumerate(param['alphas']):\n",
    "                addstr      = 'tau_%.4f' % alpha                \n",
    "                loss_epochs = []\n",
    "                pain_rnn    = PainRNN.PainRNN(input_size, hidden_size, output_size, alpha, name_act, device).to(device)\n",
    "                optimizer   = optim.Adam(pain_rnn.parameters(), lr=learning_rate)\n",
    "                criterion1  = nn.MSELoss()              # For intensity.\n",
    "                criterion2  = nn.CrossEntropyLoss()     # For clicks. if required\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "                    for inputs, targets in dataloader:\n",
    "                        \n",
    "                        add_noise  = np.random.normal(0, noise_sig, inputs.shape)\n",
    "                        inputs    += torch.from_numpy(add_noise).to(torch.float32)\n",
    "                        inputs     = inputs.to(device)\n",
    "                        outputs, _ = pain_rnn(inputs)  \n",
    "                        targets    = targets.to(device)\n",
    "                        \n",
    "                        if name_out == 'Ratings':  \n",
    "                            targets      = torch.unsqueeze(targets[:, :, 0], dim=2)\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion1(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'MSE'\n",
    "                            \n",
    "                        elif name_out == 'Clicks':\n",
    "                            targets      = torch.unsqueeze(targets[:, :, 1], dim=2)\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion2(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'CE'\n",
    "                            \n",
    "                        elif name_out == 'Clicks2':\n",
    "                            outputs_flat = outputs.view(-1, 2)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss         = criterion2(outputs_flat, targets_flat.long())\n",
    "                            loss_name    = 'CE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE':\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion1(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'MSE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE_CE':\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = outputs[:, :, 1].view(-1)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat)\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'MSE_CE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE_sigmoidCE':\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = torch.sigmoid(outputs[:, :, 1].view(-1))\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat)\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'MSE_sigmoidCE'\n",
    "                            \n",
    "                        elif name_out == 'Actions': # Does this also need sigmoid?\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = outputs[:, :, 1:].view(-1, 2)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat.long())\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'Actions'\n",
    "                            \n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    loss_epochs.append(loss.item())\n",
    "                    if ((epoch+1) % 10) == 0:\n",
    "                        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f} in {i+1} of {n_alphas}')\n",
    "            \n",
    "                out_t, h_t = pain_rnn(torch.from_numpy(np.expand_dims(Inputs, axis = 2)).to(torch.float32))\n",
    "                out_t      = out_t.detach().numpy()\n",
    "                h_t        = h_t.detach().numpy()\n",
    "\n",
    "                \n",
    "                plt.rcParams.update({\n",
    "                    'font.family': 'sans-serif',  # Use sans-serif fonts\n",
    "                    'font.sans-serif': 'Helvetica',  # Specifically Helvetica\n",
    "                    'font.size': 10  # Set font size to 10\n",
    "                })\n",
    "                fig, axes = plt.subplots(3, 3, figsize = (9, 9), constrained_layout = True)\n",
    "                axes[0, 0].plot(Inputs.T)\n",
    "                axes[0, 0].set_xlabel('time')\n",
    "                axes[0, 0].set_ylabel('Input')\n",
    "                axes[0, 0].spines['top'].set_visible(False)\n",
    "                axes[0, 0].spines['right'].set_visible(False)\n",
    "                for i in range(targets.shape[2]):\n",
    "                    axes[0, i+1].plot(targets[:, :, i].T)\n",
    "                    axes[0, i+1].set_xlabel('time')\n",
    "                    axes[0, i+1].set_ylabel(f'e.g. Labels {name_out}')\n",
    "                    axes[0, i+1].spines['top'].set_visible(False)\n",
    "                    axes[0, i+1].spines['right'].set_visible(False)\n",
    "                \n",
    "                for i in range(output_size):\n",
    "                    axes[1, i].plot(out_t[:, :, i].T)\n",
    "                    axes[1, i].set_xlabel('time')\n",
    "                    axes[1, i].set_ylabel('Outputs from the model')\n",
    "                    axes[1, i].spines['top'].set_visible(False)\n",
    "                    axes[1, i].spines['right'].set_visible(False)\n",
    "\n",
    "                axes[2, 0].plot(loss_epochs)\n",
    "                axes[2, 0].set_xlabel('Epochs')\n",
    "                axes[2, 0].set_ylabel('Loss')\n",
    "                axes[2, 0].spines['top'].set_visible(False)\n",
    "                axes[2, 0].spines['right'].set_visible(False)\n",
    "\n",
    "                axes[2, 1].plot(np.mean(h_t, 0))\n",
    "                axes[2, 1].set_xlabel('time')\n",
    "                axes[2, 1].set_ylabel(f'Hidden Units avg across {name_lvl}')\n",
    "                axes[2, 1].spines['top'].set_visible(False)\n",
    "                axes[2, 1].spines['right'].set_visible(False)\n",
    "                \n",
    "                    \n",
    "                sio.savemat(os.path.join(targfolder, ('HiddenLayers_' + addstr + '.mat')), \n",
    "                                {'out_t': out_t, 'h_t': h_t, 'loss_epochs': loss_epochs, \n",
    "                                'i2h':pain_rnn.i2h.weight.detach().numpy(), \n",
    "                                'h2h':pain_rnn.h2h.weight.detach().numpy(), \n",
    "                                'h2o':pain_rnn.h2o.weight.detach().numpy(),\n",
    "                                'Inputs': X, 'Targets': y})\n",
    "                torch.save(pain_rnn, os.path.join(targfolder, f'pain_rnn_{addstr}.pth'))\n",
    "\n",
    "                plt.savefig(os.path.join(targfolder, ('HiddenLayers_' + addstr + '.png')))\n",
    "                print(('HiddenLayers_' + addstr + '.png' + 'saved'))\n",
    "                plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
