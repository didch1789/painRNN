{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00],\n",
       "         [5.6369e-04, 0.0000e+00],\n",
       "         [1.5443e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [4.2400e-04, 0.0000e+00],\n",
       "         [2.7364e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [4.2400e-04, 0.0000e+00],\n",
       "         [2.7364e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 1.0000e+00],\n",
       "         [       nan, 1.0000e+00],\n",
       "         [       nan, 1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [5.6369e-04, 0.0000e+00],\n",
       "         [1.5443e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [2.5125e-04, 0.0000e+00],\n",
       "         [1.8195e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [4.2648e-04, 0.0000e+00],\n",
       "         [1.4749e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00],\n",
       "         [       nan, 0.0000e+00]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/3000], Loss: nan in 1 of 21\n",
      "Epoch [20/3000], Loss: nan in 1 of 21\n",
      "Epoch [30/3000], Loss: nan in 1 of 21\n",
      "Epoch [40/3000], Loss: nan in 1 of 21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 133\u001b[0m\n\u001b[1;32m    131\u001b[0m inputs    \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(add_noise)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    132\u001b[0m inputs     \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 133\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m pain_rnn(inputs)  \n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name_out \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRatings\u001b[39m\u001b[38;5;124m'\u001b[39m:  \n\u001b[1;32m    136\u001b[0m     targets      \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(targets[:, :, \u001b[38;5;241m0\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github/painRNN/PainRNN.py:41\u001b[0m, in \u001b[0;36mPainRNN.forward\u001b[0;34m(self, input, init_hidden)\u001b[0m\n\u001b[1;32m     39\u001b[0m x_t           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[:, i, :]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactfunc \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m    hidden_unit   \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2h(x_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h(h_t))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactfunc \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     43\u001b[0m    hidden_unit   \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2h(x_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h(h_t))\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 24.11.25\n",
    "# Searching all possible hyperparam space.\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import PainRNN as PainRNN\n",
    "\n",
    "param = dict()\n",
    "param['level']      = ['condition_prob'] #  'trial', 'condition'\n",
    "param['activation'] = ['relu', 'tanh']\n",
    "param['outputs']    = ['Ratings', 'Clicks2', 'Both_MSE', 'Actions'] #  'Both_MSE_CE', 'Both_MSE_sigmoidCE',\n",
    "param['alphas']     = np.linspace(0, 1, 21)\n",
    "# Clicks. CE \n",
    "# Ratings. MSE\n",
    "# Both (Ratings + Clicks). MSE + CE or MSE\n",
    "# Actions (Ratings + Click1 + Click2; Click1 - Click2 for deciding actions indicated as 0 or 1 for pain). MSE + CE or MSE \n",
    "\n",
    "# FIXED PARAMS\n",
    "input_size    = 1   # Input feature size (objective temperature)\n",
    "hidden_size   = 64  # Number of features in the hidden state\n",
    "noise_sig     = 1e-2\n",
    "learning_rate = 1e-3 \n",
    "n_epochs      = 3000\n",
    "device        = 'cpu' # mps\n",
    "# batch_size  = 50 for trial-level 9 for condition-level\n",
    "\n",
    "# Seed random number generator for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Training models for every search space\n",
    "for i_lvl, name_lvl in  enumerate(param['level']):\n",
    "    for i_act, name_act in enumerate(param['activation']):\n",
    "        for i_out, name_out in enumerate(param['outputs']):\n",
    "            \n",
    "            targfolder  = os.path.join(os.getcwd(), 'results', f'{name_lvl}_act-{name_act}_label-{name_out}')\n",
    "            if not (os.path.isdir(targfolder)):\n",
    "                os.makedirs(targfolder)\n",
    "            \n",
    "            # Specifying Inputs\n",
    "            if name_lvl == 'trial':\n",
    "                inputoutputs = sio.loadmat('InOutputs.mat')\n",
    "                Inputs   = inputoutputs['Inputs']\n",
    "                Outputs  = inputoutputs['Outputs']\n",
    "                Xnp = []\n",
    "                ynp = []\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    Xnp.append(np.tile(Inputs[cond_i, :], (Outputs[cond_i][0].shape[0], 1)))\n",
    "                    ynp.append(Outputs[cond_i][0])\n",
    "                Xnp = np.expand_dims(np.vstack(Xnp), axis=2)\n",
    "                ynp = np.vstack(ynp)\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 50\n",
    "                \n",
    "            elif name_lvl == 'condition':\n",
    "                inputoutputs = sio.loadmat('InOutputs_condavg.mat')\n",
    "                Inputs   = inputoutputs['Inputs']\n",
    "                Outputs  = inputoutputs['Outputs']\n",
    "                Xnp      = np.expand_dims(Inputs, axis = 2)\n",
    "                ynp      = []\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    ynp.append(Outputs[cond_i][0])\n",
    "                ynp         = np.stack(ynp, axis = 0)\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 9\n",
    "            \n",
    "            elif name_lvl == 'condition_prob':\n",
    "                inputoutputs = sio.loadmat('InOutputs_condavg_prob.mat')\n",
    "                n_condsample = 100\n",
    "                n_times      = inputoutputs['Inputs'].shape[1]\n",
    "                Inputs       = inputoutputs['Inputs']\n",
    "                Outputs      = inputoutputs['Outputs']\n",
    "                Xnp          = np.empty(shape=(n_condsample * 9, n_times, 1))\n",
    "                ynp          = np.empty(shape=(n_condsample * 9, n_times, 2))\n",
    "                \n",
    "                k = 0\n",
    "                for cond_i in range(len(Outputs)):\n",
    "                    input = Inputs[cond_i]\n",
    "                    for sample_i in range(n_condsample):\n",
    "                        clicks = np.zeros((n_times))\n",
    "                        rating = Outputs[cond_i, 0]\n",
    "                        click1 = round(np.random.normal(loc=Outputs[cond_i, 1][0][0], scale=Outputs[cond_i, 1][0][1]))\n",
    "                        click2 = round(np.random.normal(loc=Outputs[cond_i, 1][0][2], scale=Outputs[cond_i, 1][0][3]))\n",
    "                        if click1 > click2:\n",
    "                            click2 = click1+1\n",
    "                        if click2 > n_times:\n",
    "                            click2 = n_times\n",
    "                        clicks[click1:click2] = 1\n",
    "                        Xnp[k, :, 0] = input\n",
    "                        ynp[k, :, 0] = np.squeeze(rating)\n",
    "                        ynp[k, :, 1] = clicks\n",
    "                        k = k + 1\n",
    "\n",
    "                X = torch.from_numpy(Xnp).to(torch.float32)\n",
    "                y = torch.from_numpy(ynp).to(torch.float32)\n",
    "                batch_size = 200\n",
    "\n",
    "            # Combine inputs and outputs into a dataset\n",
    "            dataset    = TensorDataset(X, y)\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            if (name_out == 'Clicks') or (name_out == 'Ratings') :\n",
    "                output_size = 1\n",
    "            elif ('Both' in name_out) or (name_out == 'Clicks2'):\n",
    "                output_size = 2\n",
    "            elif name_out == 'Actions':\n",
    "                output_size = 3\n",
    "            \n",
    "            # Model instantiation\n",
    "            for i, alpha in enumerate(param['alphas']):\n",
    "                addstr      = 'tau_%.2f' % alpha                \n",
    "                loss_epochs = []\n",
    "                pain_rnn    = PainRNN.PainRNN(input_size, hidden_size, output_size, alpha, name_act).to(device)\n",
    "                optimizer   = optim.Adam(pain_rnn.parameters(), lr=learning_rate)\n",
    "                criterion1  = nn.MSELoss()              # For intensity.\n",
    "                criterion2  = nn.CrossEntropyLoss()     # For clicks. if required\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "                    for inputs, targets in dataloader:\n",
    "                        \n",
    "                        add_noise  = np.random.normal(0, noise_sig, inputs.shape)\n",
    "                        inputs    += torch.from_numpy(add_noise).to(torch.float32)\n",
    "                        inputs     = inputs.to(device)\n",
    "                        outputs, _ = pain_rnn(inputs)  \n",
    "                        \n",
    "                        if name_out == 'Ratings':  \n",
    "                            targets      = torch.unsqueeze(targets[:, :, 0], dim=2)\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion1(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'MSE'\n",
    "                            \n",
    "                        elif name_out == 'Clicks':\n",
    "                            targets      = torch.unsqueeze(targets[:, :, 1], dim=2)\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion2(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'CE'\n",
    "                            \n",
    "                        elif name_out == 'Clicks2':\n",
    "                            outputs_flat = outputs.view(-1, 2)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss         = criterion2(outputs_flat, targets_flat.long())\n",
    "                            loss_name    = 'CE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE':\n",
    "                            outputs_flat = outputs.view(-1)\n",
    "                            targets_flat = targets.view(-1)\n",
    "                            loss         = criterion1(outputs_flat, targets_flat)\n",
    "                            loss_name    = 'MSE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE_CE':\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = outputs[:, :, 1].view(-1)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat)\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'MSE_CE'\n",
    "                            \n",
    "                        elif name_out == 'Both_MSE_sigmoidCE':\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = torch.sigmoid(outputs[:, :, 1].view(-1))\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat)\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'MSE_sigmoidCE'\n",
    "                            \n",
    "                        elif name_out == 'Actions': # Does this also need sigmoid?\n",
    "                            outputs_flat = outputs[:, :, 0].view(-1)\n",
    "                            targets_flat = targets[:, :, 0].view(-1)\n",
    "                            loss1        = criterion1(outputs_flat, targets_flat)\n",
    "                            outputs_flat = outputs[:, :, 1:].view(-1, 2)\n",
    "                            targets_flat = targets[:, :, 1].view(-1)\n",
    "                            loss2        = criterion2(outputs_flat, targets_flat.long())\n",
    "                            loss         = loss1 + loss2\n",
    "                            loss_name    = 'Actions'\n",
    "                            \n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    loss_epochs.append(loss.item())\n",
    "                    if ((epoch+1) % 10) == 0:\n",
    "                        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f} in {i+1} of {len(param['alphas'])}')\n",
    "            \n",
    "                out_t, h_t = pain_rnn(torch.from_numpy(np.expand_dims(Inputs, axis = 2)).to(torch.float32))\n",
    "                out_t      = out_t.detach().numpy()\n",
    "                h_t        = h_t.detach().numpy()\n",
    "\n",
    "                \n",
    "                plt.rcParams.update({\n",
    "                    'font.family': 'sans-serif',  # Use sans-serif fonts\n",
    "                    'font.sans-serif': 'Helvetica',  # Specifically Helvetica\n",
    "                    'font.size': 10  # Set font size to 10\n",
    "                })\n",
    "                fig, axes = plt.subplots(3, 3, figsize = (9, 9), constrained_layout = True)\n",
    "                axes[0, 0].plot(Inputs.T)\n",
    "                axes[0, 0].set_xlabel('time')\n",
    "                axes[0, 0].set_ylabel('Input')\n",
    "                axes[0, 0].spines['top'].set_visible(False)\n",
    "                axes[0, 0].spines['right'].set_visible(False)\n",
    "                for i in range(targets.shape[2]):\n",
    "                    axes[0, i+1].plot(targets[:, :, i].T)\n",
    "                    axes[0, i+1].set_xlabel('time')\n",
    "                    axes[0, i+1].set_ylabel(f'e.g. Labels {name_out}')\n",
    "                    axes[0, i+1].spines['top'].set_visible(False)\n",
    "                    axes[0, i+1].spines['right'].set_visible(False)\n",
    "                \n",
    "                for i in range(output_size):\n",
    "                    axes[1, i].plot(out_t[:, :, i].T)\n",
    "                    axes[1, i].set_xlabel('time')\n",
    "                    axes[1, i].set_ylabel('Outputs from the model')\n",
    "                    axes[1, i].spines['top'].set_visible(False)\n",
    "                    axes[1, i].spines['right'].set_visible(False)\n",
    "\n",
    "                axes[2, 0].plot(loss_epochs)\n",
    "                axes[2, 0].set_xlabel('Epochs')\n",
    "                axes[2, 0].set_ylabel('Loss')\n",
    "                axes[2, 0].spines['top'].set_visible(False)\n",
    "                axes[2, 0].spines['right'].set_visible(False)\n",
    "\n",
    "                axes[2, 1].plot(np.mean(h_t, 0))\n",
    "                axes[2, 1].set_xlabel('time')\n",
    "                axes[2, 1].set_ylabel(f'Hidden Units avg across {name_lvl}')\n",
    "                axes[2, 1].spines['top'].set_visible(False)\n",
    "                axes[2, 1].spines['right'].set_visible(False)\n",
    "                \n",
    "                    \n",
    "                sio.savemat(os.path.join(targfolder, ('HiddenLayers_' + addstr + '.mat')), \n",
    "                                {'out_t': out_t, 'h_t': h_t, 'loss_epochs': loss_epochs, \n",
    "                                'i2h':pain_rnn.i2h.weight.detach().numpy(), \n",
    "                                'h2h':pain_rnn.h2h.weight.detach().numpy(), \n",
    "                                'h2o':pain_rnn.h2o.weight.detach().numpy(),\n",
    "                                'Inputs': Inputs, 'Targets': targets})\n",
    "\n",
    "                plt.savefig(os.path.join(targfolder, ('HiddenLayers_' + addstr + '.png')))\n",
    "                plt.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
